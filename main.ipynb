{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb557f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from agents import Agent, Runner, trace, function_tool,OpenAIChatCompletionsModel\n",
    "import langsmith\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fadd07f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936140a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Make sure your .env file exists in the project root\n",
    "\n",
    "# Setup LangSmith client\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "client_ls = langsmith.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b9b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae71e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "gemini_model = OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=gemini_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73d95dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Client.list_runs at 0x000002DCE06C3A60>\n"
     ]
    }
   ],
   "source": [
    "client = langsmith.Client(\n",
    "    api_key=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    ")\n",
    "\n",
    "# Optional: test connection\n",
    "print(client.list_runs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d5d702e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, let's break down 10 basic principles of economics in a simple, easy-to-understand way! Think of these as the rules of the game when it comes to understanding how people make choices about money, resources, and well-being.\n",
      "\n",
      "**1. People Face Trade-offs:**\n",
      "\n",
      "*   **In Simple Terms:** You can't have everything. If you spend time studying, you have less time to hang out with friends. Every choice means giving up something else.\n",
      "*   **Example:** A government can spend money on education or on defense, but spending more on one means less for the other.\n",
      "\n",
      "**2. The Cost of Something Is What You Give Up to Get It (Opportunity Cost):**\n",
      "\n",
      "*   **In Simple Terms:** The *real* cost of something isn't just the money, it's what else you *could* have done with that money or time.\n",
      "*   **Example:** The opportunity cost of going to college isn't just tuition and books. It's also the money you *could* have earned if you were working instead.\n",
      "\n",
      "**3. Rational People Think at the Margin:**\n",
      "\n",
      "*   **In Simple Terms:** Most decisions aren't all-or-nothing. We usually make choices in small steps, thinking about the *additional* benefit versus the *additional* cost.\n",
      "*   **Example:** A company doesn't decide to produce *all* or *none* of a product. They decide whether to produce *one more unit* based on if the extra revenue from that unit exceeds the extra cost.\n",
      "\n",
      "**4. People Respond to Incentives:**\n",
      "\n",
      "*   **In Simple Terms:** People change their behavior when something motivates them, whether it's a reward or a punishment.\n",
      "*   **Example:** If gas prices rise, people might drive less or buy more fuel-efficient cars.\n",
      "\n",
      "**5. Trade Can Make Everyone Better Off:**\n",
      "\n",
      "*   **In Simple Terms:** By trading with each other, countries (or individuals) can specialize in what they do best and get a greater variety of goods and services.\n",
      "*   **Example:** The US might specialize in technology and Australia in mining. Both countries benefit by trading these goods.\n",
      "\n",
      "**6. Markets Are Usually a Good Way to Organize Economic Activity:**\n",
      "\n",
      "*   **In Simple Terms:** Markets (where buyers and sellers interact) are generally a good way to decide what goods and services to produce, how much to produce, and who gets them. Prices act like signals, guiding these decisions.\n",
      "*   **Example:** Instead of the government deciding how many phones to make, the market does. If people want more phones, the price goes up, encouraging companies to make more.\n",
      "\n",
      "**7. Governments Can Sometimes Improve Market Outcomes:**\n",
      "\n",
      "*   **In Simple Terms:** Sometimes markets don't work perfectly on their own. Governments can step in to fix problems like pollution, provide public goods (like roads), or make things fairer.\n",
      "*   **Example:** The government might regulate pollution to protect the environment or provide national defense because the market wouldn't efficiently provide it.\n",
      "\n",
      "**8. A Country's Standard of Living Depends on Its Ability to Produce Goods and Services:**\n",
      "\n",
      "*   **In Simple Terms:** The more goods and services a country can produce, the wealthier its citizens will be, on average.\n",
      "*   **Example:** Countries with higher productivity (meaning they can produce more with the same resources) tend to have higher standards of living.\n",
      "\n",
      "**9. Prices Rise When the Government Prints Too Much Money (Inflation):**\n",
      "\n",
      "*   **In Simple Terms:** If there's too much money chasing too few goods, the value of money decreases, and prices go up.\n",
      "*   **Example:** If the government doubles the amount of money in the economy without increasing the production of goods, prices will likely double too.\n",
      "\n",
      "**10. Society Faces a Short-Run Trade-off between Inflation and Unemployment:**\n",
      "\n",
      "*   **In Simple Terms:** In the short term, policies aimed at lowering inflation may lead to higher unemployment, and vice versa. There's often a temporary push and pull between these two.\n",
      "*   **Example:** If the government tries to quickly reduce inflation by raising interest rates, it might slow down the economy and cause some businesses to lay off workers.\n",
      "\n",
      "So, there you have it! Ten basic principles of economics, explained in a simple way. Keep these in mind, and you'll have a solid foundation for understanding how the economic world works!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(\n",
    "    name=\"educator-agent\",\n",
    "    model=gemini_model,\n",
    "    instructions=\"You are an educator. Explain concepts simply.\"\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, \"Explain 10 basic principles of economics\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b88c0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the agent with LangSmith tracing...\n",
      "\n",
      "Agent's final output:\n",
      "\n",
      "Alright, let's break down 10 basic principles of economics in a way that's easy to understand! Think of these as guidelines for understanding how people make decisions and how economies work.\n",
      "\n",
      "**1. People Face Trade-offs:**\n",
      "\n",
      "*   **Imagine:** You only have $5. You can buy a coffee OR a snack. You can't have both!\n",
      "*   **Explanation:** Every choice means giving up something else. Resources are limited, so we always have to decide what's most important to us.\n",
      "\n",
      "**2. The Cost of Something Is What You Give Up to Get It (Opportunity Cost):**\n",
      "\n",
      "*   **Imagine:** You choose to spend an hour playing video games instead of working.\n",
      "*   **Explanation:** The *real* cost isn't just the time, it's also the money you *could* have earned working. That missed income is the \"opportunity cost.\"\n",
      "\n",
      "**3. Rational People Think at the Margin:**\n",
      "\n",
      "*   **Imagine:** A restaurant is deciding whether to stay open an extra hour.\n",
      "*   **Explanation:** They'll compare the *additional* revenue they'd make (marginal benefit) to the *additional* costs (marginal cost). If the benefit is greater, they'll stay open. It's about making small adjustments based on the extra impact.\n",
      "\n",
      "**4. People Respond to Incentives:**\n",
      "\n",
      "*   **Imagine:** A store has a sale on your favorite candy.\n",
      "*   **Explanation:** You're more likely to buy the candy because the lower price (the incentive) makes it more appealing. Incentives can be rewards or punishments that influence behavior.\n",
      "\n",
      "**5. Trade Can Make Everyone Better Off:**\n",
      "\n",
      "*   **Imagine:** You're good at baking, and your friend is good at gardening.\n",
      "*   **Explanation:** If you trade, you get fresh vegetables, and your friend gets delicious cake! Everyone benefits when people specialize and trade their skills or goods.\n",
      "\n",
      "**6. Markets Are Usually a Good Way to Organize Economic Activity:**\n",
      "\n",
      "*   **Imagine:** A farmer's market where buyers and sellers come together.\n",
      "*   **Explanation:** In a market economy, prices are determined by the interactions of buyers and sellers. This system usually leads to goods and services being produced efficiently and allocated to those who value them most.\n",
      "\n",
      "**7. Governments Can Sometimes Improve Market Outcomes:**\n",
      "\n",
      "*   **Imagine:** A factory is polluting a river, harming the community.\n",
      "*   **Explanation:** The government can step in to regulate pollution, protect property rights, or provide public goods (like roads) that the market wouldn't provide on its own.\n",
      "\n",
      "**8. A Country's Standard of Living Depends on Its Ability to Produce Goods and Services:**\n",
      "\n",
      "*   **Imagine:** A country where people are highly skilled and use advanced technology.\n",
      "*   **Explanation:** That country will likely produce more goods and services, leading to higher incomes and a better quality of life for its citizens. Productivity is key!\n",
      "\n",
      "**9. Prices Rise When the Government Prints Too Much Money (Inflation):**\n",
      "\n",
      "*   **Imagine:** The government suddenly doubles the amount of money in the economy.\n",
      "*   **Explanation:** If there are still the same amount of goods and services available, but twice as much money chasing them, prices will go up.\n",
      "\n",
      "**10. Society Faces a Short-Run Trade-off Between Inflation and Unemployment:**\n",
      "\n",
      "*   **Imagine:** The government tries to lower unemployment by increasing spending.\n",
      "*   **Explanation:** This might create jobs in the short term, but it could also lead to higher inflation. Policymakers constantly grapple with this trade-off. There is usually a lag time before new policies and projects have an impact.\n",
      "\n",
      "**In a nutshell:** Economics is all about understanding how people make choices in the face of scarcity and how those choices affect the world around us.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, Runner, OpenAIChatCompletionsModel\n",
    "from langsmith import Client, traceable\n",
    "import asyncio\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up LangSmith client\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "client_ls = Client()\n",
    "\n",
    "# Set up the OpenAI client for the Gemini model\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "gemini_model = OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=gemini_client)\n",
    "\n",
    "# Define the agent\n",
    "agent = Agent(\n",
    "    name=\"educator-agent\",\n",
    "    model=gemini_model,\n",
    "    instructions=\"You are an educator. Explain concepts simply.\"\n",
    ")\n",
    "\n",
    "# Use @traceable from langsmith to trace the agent's run\n",
    "@traceable(name=\"educator-agent-run\")\n",
    "async def run_traced_agent(agent_instance, user_query):\n",
    "    \"\"\"A traced function to run the agent.\"\"\"\n",
    "    return await Runner.run(agent_instance, user_query)\n",
    "\n",
    "# Main function to run the agent\n",
    "async def main():\n",
    "    print(\"Running the agent with LangSmith tracing...\")\n",
    "    try:\n",
    "        result = await run_traced_agent(agent, \"Explain 10 basic principles of economics\")\n",
    "        print(\"\\nAgent's final output:\\n\")\n",
    "        print(result.final_output)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# This is the new, platform-independent way to run the coroutine\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        loop.run_until_complete(main())\n",
    "    except RuntimeError:\n",
    "        asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c698ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ecc058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the agent with LangSmith tracing...\n",
      "\n",
      "Agent's final output:\n",
      "\n",
      "Alright, let's break down 10 basic principles of economics in a simple and easy-to-understand way! Think of these as guidelines for understanding how people make choices and how those choices impact the world around us.\n",
      "\n",
      "**1. People Face Trade-offs:**\n",
      "\n",
      "*   **The Idea:** We can't have everything we want. Choosing one thing means giving up something else.\n",
      "*   **Example:** You have to decide whether to spend your time studying or hanging out with friends. You can't do both at the same time.\n",
      "\n",
      "**2. The Cost of Something Is What You Give Up to Get It (Opportunity Cost):**\n",
      "\n",
      "*   **The Idea:**  The true cost of something isn't just the money you pay, but also the value of the next best thing you could have done with that money or time.\n",
      "*   **Example:**  The opportunity cost of going to college isn't just tuition, but also the money you could have earned working full-time instead.\n",
      "\n",
      "**3. Rational People Think at the Margin:**\n",
      "\n",
      "*   **The Idea:** Smart decisions are made by considering the additional benefit (marginal benefit) versus the additional cost (marginal cost) of a little bit more or a little bit less of something.\n",
      "*   **Example:**  A company deciding whether to produce one more widget looks at the extra revenue from selling it and compares that to the extra cost of making it.\n",
      "\n",
      "**4. People Respond to Incentives:**\n",
      "\n",
      "*   **The Idea:** People change their behavior when they are rewarded or punished for it.\n",
      "*   **Example:** If a store has a sale, more people will buy things. If there's a tax on cigarettes, fewer people will smoke.\n",
      "\n",
      "**5. Trade Can Make Everyone Better Off:**\n",
      "\n",
      "*   **The Idea:**  When people and countries specialize in what they do best and then trade with each other, everyone can end up with more and better goods and services.\n",
      "*   **Example:** You might be good at cooking, and your friend might be good at cleaning. If you trade – you cook, they clean – you both end up better off.\n",
      "\n",
      "**6. Markets Are Usually a Good Way to Organize Economic Activity:**\n",
      "\n",
      "*   **The Idea:**  Markets, where buyers and sellers interact, usually lead to the efficient production and allocation of goods and services. Prices act as signals to guide decisions.\n",
      "*   **Example:**  Think of a farmer's market.  Farmers decide what to grow based on what people want to buy, and buyers get the products they need at prices they're willing to pay.\n",
      "\n",
      "**7. Governments Can Sometimes Improve Market Outcomes:**\n",
      "\n",
      "*   **The Idea:** Sometimes markets fail to allocate resources efficiently (market failures). Governments can step in to fix these failures through things like regulations, taxes, and public goods.\n",
      "*   **Example:** Pollution is a market failure. The government can regulate pollution to protect the environment.\n",
      "\n",
      "**8. A Country's Standard of Living Depends on Its Ability to Produce Goods and Services:**\n",
      "\n",
      "*   **The Idea:** The more productive a country is (i.e., the more goods and services it can produce per person), the higher its standard of living will be.\n",
      "*   **Example:** Countries with advanced technology and skilled workers tend to be wealthier than countries without those things.\n",
      "\n",
      "**9. Prices Rise When the Government Prints Too Much Money (Inflation):**\n",
      "\n",
      "*   **The Idea:** When there's too much money in circulation, the value of money decreases, and prices go up.\n",
      "*   **Example:** If the government doubles the amount of money in the economy without increasing the amount of goods and services, everything will eventually cost about twice as much.\n",
      "\n",
      "**10. Society Faces a Short-Run Trade-off Between Inflation and Unemployment:**\n",
      "\n",
      "*   **The Idea:** In the short-run, policies that reduce inflation may lead to higher unemployment, and policies that reduce unemployment may lead to higher inflation. This is a complex and debated topic.\n",
      "*   **Example:** If the government tries to slow down the economy to control inflation, businesses may lay off workers, leading to higher unemployment.\n",
      "\n",
      "And there you have it! 10 basic principles of economics explained simply. These principles provide a foundation for understanding how economies work and how people make decisions in the face of scarcity. Remember these, and you'll be well on your way to understanding the economic world around you!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, Runner, OpenAIChatCompletionsModel\n",
    "from langsmith import Client, traceable\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply the patch for nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up LangSmith client\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "client_ls = Client()\n",
    "\n",
    "# Set up the OpenAI client for the Gemini model\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "gemini_model = OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=gemini_client)\n",
    "\n",
    "# Define the agent\n",
    "agent = Agent(\n",
    "    name=\"educator-agent\",\n",
    "    model=gemini_model,\n",
    "    instructions=\"You are an educator. Explain concepts simply.\"\n",
    ")\n",
    "\n",
    "# Use @traceable from langsmith to trace the agent's run\n",
    "@traceable(name=\"educator-agent-run\")\n",
    "async def run_traced_agent(agent_instance, user_query):\n",
    "    \"\"\"A traced function to run the agent.\"\"\"\n",
    "    return await Runner.run(agent_instance, user_query)\n",
    "\n",
    "# Main function to run the agent\n",
    "async def main():\n",
    "    print(\"Running the agent with LangSmith tracing...\")\n",
    "    try:\n",
    "        result = await run_traced_agent(agent, \"Explain 10 basic principles of economics\")\n",
    "        print(\"\\nAgent's final output:\\n\")\n",
    "        print(result.final_output)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the main function using the standard method\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46270f6",
   "metadata": {},
   "source": [
    "### Creating NEWS API Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4c5694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from newsapi import NewsApiClient\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Initialize with API key from .env\n",
    "newsapi = NewsApiClient(api_key=os.getenv(\"NEWSAPI_KEY\"))\n",
    "\n",
    "@tool\n",
    "def fetch_news(query: str, language: str = \"en\", country: str = \"us\", max_results: int = 5):\n",
    "    \"\"\"\n",
    "    Fetch top headlines for a given query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search keyword (e.g., 'economics', 'inflation')\n",
    "        language (str): Language of the articles (default 'en')\n",
    "        country (str): Country code (default 'us')\n",
    "        max_results (int): Number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        list of dict: A list of news articles (title + URL)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headlines = newsapi.get_top_headlines(q=query, language=language, country=country)\n",
    "        articles = headlines.get(\"articles\", [])\n",
    "        \n",
    "        return [\n",
    "            {\"title\": a[\"title\"], \"url\": a[\"url\"]}\n",
    "            for a in articles[:max_results]\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        return [{\"error\": str(e)}]\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86692397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Wrap fetch_news as a proper tool\n",
    "fetch_news_tool = Tool(\n",
    "    name=\"fetch_news\",\n",
    "    description=\"Fetch top headlines for a given keyword, language, and country.\",\n",
    "    func=fetch_news,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45f298d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the agent with LangSmith tracing...\n",
      "An error occurred: Hosted tools are not supported with the ChatCompletions API. Got tool type: <class 'langchain_core.tools.structured.StructuredTool'>, tool: name='fetch_news' description=\"Fetch top headlines for a given query.\\n\\nArgs:\\n    query (str): The search keyword (e.g., 'economics', 'inflation')\\n    language (str): Language of the articles (default 'en')\\n    country (str): Country code (default 'us')\\n    max_results (int): Number of results to return\\n\\nReturns:\\n    list of dict: A list of news articles (title + URL)\" args_schema=<class 'langchain_core.utils.pydantic.fetch_news'> func=<function fetch_news at 0x000002DCB6711440>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the agent\n",
    "agent = Agent(\n",
    "    name=\"educator-agent\",\n",
    "    model=gemini_model,\n",
    "    instructions=\"You are an educator. Explain concepts simply.Give real world examples everytime you explain a concept.\",\n",
    "    tools=[fetch_news]\n",
    ")\n",
    "\n",
    "# Use @traceable from langsmith to trace the agent's run\n",
    "@traceable(name=\"educator-agent-run\")\n",
    "async def run_traced_agent(agent_instance, user_query):\n",
    "    \"\"\"A traced function to run the agent.\"\"\"\n",
    "    return await Runner.run(agent_instance, user_query)\n",
    "\n",
    "# Main function to run the agent\n",
    "async def main():\n",
    "    print(\"Running the agent with LangSmith tracing...\")\n",
    "    try:\n",
    "        result = await run_traced_agent(agent, \"Explain the 9th principle of economics.\")\n",
    "        print(\"\\nAgent's final output:\\n\")\n",
    "        print(result.final_output)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the main function using the standard method\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a45c5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the agent with LangSmith tracing...\n",
      "Function called\n",
      "{'status': 'ok', 'totalResults': 0, 'articles': []}\n",
      "[]\n",
      "\n",
      "Agent's final output:\n",
      "\n",
      "I am sorry, I cannot fulfill this request. The news API is not returning any results for your query. This may be a temporary issue. Please try again later.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, Runner, OpenAIChatCompletionsModel, function_tool\n",
    "from langsmith import Client, traceable\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from langchain_core.tools import tool\n",
    "from newsapi import NewsApiClient\n",
    "from agents import Agent, FileSearchTool, Runner, WebSearchTool\n",
    "\n",
    "# Apply the patch for nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up LangSmith client\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "client_ls = Client()\n",
    "\n",
    "# Set up the OpenAI client for the Gemini model using the compatible endpoint\n",
    "# This is where the tool-calling issue might stem from.\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "gemini_model = OpenAIChatCompletionsModel(model=\"gemini-2.5-pro\", openai_client=gemini_client)\n",
    "\n",
    "# Initialize NewsAPI client\n",
    "newsapi = NewsApiClient(api_key=os.getenv(\"NEWSAPI_KEY\"))\n",
    "\n",
    "# Define the news fetching tool\n",
    "@function_tool\n",
    "def fetch_news(query: str, language: str = \"en\", country: str = \"us\", max_results: int = 5):\n",
    "    \"\"\"\n",
    "    Fetch top headlines for a given query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search keyword (e.g., 'economics', 'inflation')\n",
    "        language (str): Language of the articles (default 'en')\n",
    "        country (str): Country code (default 'us')\n",
    "        max_results (int): Number of results to return\n",
    "\n",
    "    Returns:\n",
    "        list of dict: A list of news articles (title + URL)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # The NewsAPI client's get_top_headlines method is synchronous.\n",
    "        # If your Agent/Runner expects async tools, this might need an async wrapper.\n",
    "        headlines = newsapi.get_top_headlines(q=query, language=language, country=country)\n",
    "        print(\"Function called\")\n",
    "        print(headlines)\n",
    "        articles = headlines.get(\"articles\", [])\n",
    "        print(articles)\n",
    "\n",
    "        return [\n",
    "            {\"title\": a[\"title\"], \"url\": a[\"url\"]}\n",
    "            for a in articles[:max_results]\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        return [{\"error\": str(e)}]\n",
    "\n",
    "# Define the agent\n",
    "agent = Agent(\n",
    "    name=\"educator-agent\",\n",
    "    model=gemini_model,\n",
    "    instructions=\"You are an educator. Explain concepts simply. Give real-world examples every time you explain a concept.\",\n",
    "    tools=[fetch_news] # Pass the tool here\n",
    ")\n",
    "\n",
    "# Use @traceable from langsmith to trace the agent's run\n",
    "@traceable(name=\"educator-agent-run\")\n",
    "async def run_traced_agent(agent_instance, user_query):\n",
    "    \"\"\"A traced function to run the agent.\"\"\"\n",
    "    # Runner.run should handle invoking the tools if the model decides to use them\n",
    "    # and if the model/API supports it.\n",
    "    return await Runner.run(agent_instance, user_query)\n",
    "\n",
    "# Main function to run the agent\n",
    "async def main():\n",
    "    print(\"Running the agent with LangSmith tracing...\")\n",
    "    try:\n",
    "        # Example prompt that might trigger the news tool\n",
    "        result = await run_traced_agent(agent, \"Find the top 5 news headlines on economic growth in india and explain them to me using fetch_tools.\")\n",
    "        print(\"\\nAgent's final output:\\n\")\n",
    "        print(result.final_output)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a1468c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def fetch_news_new(query: str, language: str = \"en\", sort_by: str = \"relevancy\", max_results: int = 2):\n",
    "    \"\"\"\n",
    "    Search for articles about a given topic and return the title and description.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search keyword (e.g., 'economics', 'inflation').\n",
    "        language (str): Language of the articles (default 'en').\n",
    "        sort_by (str): The order to sort articles in ('relevancy', 'popularity', or 'publishedAt').\n",
    "        max_results (int): Number of articles to return (max 100).\n",
    "\n",
    "    Returns:\n",
    "        list of dict: A list of news articles (title and description).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use get_everything() to get both titles and descriptions\n",
    "        articles_response = newsapi.get_everything(\n",
    "            q=query,\n",
    "            language=language,\n",
    "            sort_by=sort_by,\n",
    "            page_size=max_results  # Use page_size to limit the results\n",
    "        )\n",
    "        \n",
    "        articles = articles_response.get(\"articles\", [])\n",
    "\n",
    "        # Extract only the title and description for each article\n",
    "        extracted_info = [\n",
    "            {\"title\": a.get(\"title\"), \"description\": a.get(\"description\")}\n",
    "            for a in articles\n",
    "            if a.get(\"title\") and a.get(\"description\") # Ensure both fields exist\n",
    "        ]\n",
    "        \n",
    "        return extracted_info\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f14f4eed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPSConnectionPool(host='newsapi.org', port=443): Max retries exceeded with url: /v2/everything?q=Trump&language=en&sortBy=relevancy&page=2 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002DCEE6E43D0>, 'Connection to newsapi.org timed out. (connect timeout=30)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m sock.connect(sa)\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mTimeoutError\u001b[39m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectTimeoutError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\urllib3\\connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    752\u001b[39m sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\urllib3\\connection.py:207\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[32m    208\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    209\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConnection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.host\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.timeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    210\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mConnectTimeoutError\u001b[39m: (<urllib3.connection.HTTPSConnection object at 0x000002DCEE6E43D0>, 'Connection to newsapi.org timed out. (connect timeout=30)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='newsapi.org', port=443): Max retries exceeded with url: /v2/everything?q=Trump&language=en&sortBy=relevancy&page=2 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002DCEE6E43D0>, 'Connection to newsapi.org timed out. (connect timeout=30)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectTimeout\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[116]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m newsapi = NewsApiClient(api_key=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mNEWSAPI_KEY\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# /v2/everything\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m all_articles = \u001b[43mnewsapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_everything\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTrump\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                                      \u001b[49m\u001b[38;5;66;43;03m#sources='bbc-news,the-verge',\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m                                      \u001b[49m\u001b[38;5;66;43;03m#domains='bbc.co.uk,techcrunch.com',\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m                                      \u001b[49m\u001b[38;5;66;43;03m#from_param='2017-12-01',\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m                                      \u001b[49m\u001b[38;5;66;43;03m#to='2017-12-12',\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43men\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43msort_by\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelevancy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m all_articles[\u001b[33m'\u001b[39m\u001b[33marticles\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(i[\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\newsapi\\newsapi_client.py:330\u001b[39m, in \u001b[36mNewsApiClient.get_everything\u001b[39m\u001b[34m(self, q, qintitle, sources, domains, exclude_domains, from_param, to, language, sort_by, page, page_size)\u001b[39m\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mpage param should be an int\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# Send Request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEVERYTHING_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;66;03m# Check Status of Request\u001b[39;00m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r.status_code != requests.codes.ok:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project Alpha\\Agentic AI based Educator\\Agentic-AI-Education-Platform\\agentic-ai\\Lib\\site-packages\\requests\\adapters.py:665\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, ConnectTimeoutError):\n\u001b[32m    663\u001b[39m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[32m    664\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, NewConnectionError):\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request=request)\n\u001b[32m    667\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, ResponseError):\n\u001b[32m    668\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request=request)\n",
      "\u001b[31mConnectTimeout\u001b[39m: HTTPSConnectionPool(host='newsapi.org', port=443): Max retries exceeded with url: /v2/everything?q=Trump&language=en&sortBy=relevancy&page=2 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002DCEE6E43D0>, 'Connection to newsapi.org timed out. (connect timeout=30)'))"
     ]
    }
   ],
   "source": [
    "from newsapi import NewsApiClient\n",
    "\n",
    "# Init\n",
    "newsapi = NewsApiClient(api_key=os.getenv(\"NEWSAPI_KEY\"))\n",
    "\n",
    "# /v2/everything\n",
    "all_articles = newsapi.get_everything(q='Trump',\n",
    "                                      #sources='bbc-news,the-verge',\n",
    "                                      #domains='bbc.co.uk,techcrunch.com',\n",
    "                                      #from_param='2017-12-01',\n",
    "                                      #to='2017-12-12',\n",
    "                                      language='en',\n",
    "                                      sort_by='relevancy',\n",
    "                                      page=2)\n",
    "\n",
    "for i in all_articles['articles']:\n",
    "    print(i['title'])\n",
    "    print(i['description'])\n",
    "\n",
    "articles = all_articles.get('articles')\n",
    "print(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbff7a4",
   "metadata": {},
   "source": [
    "### New API Integration successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30effd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the agent with LangSmith tracing...\n",
      "\n",
      "Agent's final output:\n",
      "\n",
      "It seems my news search tool is coming up empty on this topic, which is a bit surprising!\n",
      "\n",
      "However, the case of **Zimbabwe** in the late 2000s is such a clear and powerful real-world example of this principle that we don't need a specific article to understand it.\n",
      "\n",
      "### News from the Real World: The Case of Zimbabwe\n",
      "\n",
      "From 2007 to 2009, the government of Zimbabwe faced massive debt and economic hardship. To pay its bills, soldiers, and government workers, it began printing money at an astonishing rate.\n",
      "\n",
      "**What happened next?**\n",
      "\n",
      "1.  **More Money, Same Stuff:** Suddenly, there was a flood of new Zimbabwean dollars in the country. But the number of things to buy—loaves of bread, gallons of milk, cars—hadn't changed.\n",
      "2.  **Prices Skyrocketed:** With trillions of new dollars chasing the same amount of goods, prices exploded. Shopkeepers would change their prices several times a day. A loaf of bread might cost 10 million dollars in the morning and 50 million by the afternoon.\n",
      "3.  **Money Became Worthless:** The government had to print bills in bigger and bigger denominations. It famously issued a **100 Trillion Dollar** banknote, which was barely enough to buy a week's worth of groceries.\n",
      "\n",
      "Eventually, the Zimbabwean dollar became so worthless that people simply stopped using it. They switched to more stable foreign currencies like the U.S. dollar, even for everyday transactions.\n",
      "\n",
      "### Tying it all together:\n",
      "\n",
      "Zimbabwe's situation is a perfect, if extreme, illustration of the 9th principle. The government printed vast quantities of money, which didn't create more real-world value. It simply made the money itself less valuable, causing prices for everything to rise to unimaginable levels.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, Runner, OpenAIChatCompletionsModel, function_tool\n",
    "from langsmith import Client, traceable\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from langchain_core.tools import tool\n",
    "from newsapi import NewsApiClient\n",
    "from agents import Agent, FileSearchTool, Runner, WebSearchTool\n",
    "\n",
    "# Apply the patch for nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up LangSmith client\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "client_ls = Client()\n",
    "\n",
    "# Set up the OpenAI client for the Gemini model using the compatible endpoint\n",
    "# This is where the tool-calling issue might stem from.\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "gemini_model = OpenAIChatCompletionsModel(model=\"gemini-2.5-pro\", openai_client=gemini_client)\n",
    "\n",
    "# Initialize NewsAPI client\n",
    "newsapi = NewsApiClient(api_key=os.getenv(\"NEWSAPI_KEY\"))\n",
    "\n",
    "# Define the news fetching tool\n",
    "\n",
    "@function_tool\n",
    "@traceable(run_type=\"tool\", name=\"Fetch News Tool\")\n",
    "def fetch_news_new(query: str, language: str = \"en\", sort_by: str = \"relevancy\", max_results: int = 2):\n",
    "    \"\"\"\n",
    "    Search for articles about a given topic and return the title and description.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search keyword (e.g., 'economics', 'inflation').\n",
    "        language (str): Language of the articles (default 'en').\n",
    "        sort_by (str): The order to sort articles in ('relevancy', 'popularity', or 'publishedAt').\n",
    "        max_results (int): Number of articles to return (max 100).\n",
    "\n",
    "    Returns:\n",
    "        list of dict: A list of news articles (title and description).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use get_everything() to get both titles and descriptions\n",
    "        articles_response = newsapi.get_everything(\n",
    "            q=query,\n",
    "            language=language,\n",
    "            sort_by=sort_by,\n",
    "            page_size=max_results  # Use page_size to limit the results\n",
    "        )\n",
    "        \n",
    "        articles = articles_response.get(\"articles\", [])\n",
    "\n",
    "        # Extract only the title and description for each article\n",
    "        extracted_info = [\n",
    "            {\"title\": a.get(\"title\"), \"description\": a.get(\"description\")}\n",
    "            for a in articles\n",
    "            if a.get(\"title\") and a.get(\"description\") # Ensure both fields exist\n",
    "        ]\n",
    "        \n",
    "        return extracted_info\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "@function_tool\n",
    "@traceable(run_type=\"tool\", name=\"Fetch weather Tool\")\n",
    "def get_weather(city: str):\n",
    "    print(f\"[debug] getting weather for {city}\")\n",
    "    return f\"The weather in {city} is rainy.\"\n",
    "\n",
    "\n",
    "# Define the agent\n",
    "agent = Agent(\n",
    "    name=\"educator-agent\",\n",
    "    #model=\"litellm/gemini/gemini-1.5-flash-latest\",\n",
    "    model=gemini_model,\n",
    "    instructions=\"You are an educator. Explain concepts simply. Give real-world examples every time you explain a concept.\",\n",
    "    tools=[get_weather, fetch_news_new] # Pass the tool here\n",
    ")\n",
    "\n",
    "# Use @traceable from langsmith to trace the agent's run\n",
    "@traceable(name=\"educator-agent-run\")\n",
    "async def run_traced_agent(agent_instance, user_query):\n",
    "    \"\"\"A traced function to run the agent.\"\"\"\n",
    "    # Runner.run should handle invoking the tools if the model decides to use them\n",
    "    # and if the model/API supports it.\n",
    "    return await Runner.run(agent_instance, user_query)\n",
    "\n",
    "# Main function to run the agent\n",
    "async def main():\n",
    "    print(\"Running the agent with LangSmith tracing...\")\n",
    "    try:\n",
    "        # Example prompt that might trigger the news tool\n",
    "        result = await run_traced_agent(agent, \"Explain the 9th principle of economics with the help of news.\")\n",
    "        print(\"\\nAgent's final output:\\n\")\n",
    "        print(result.final_output)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e652830b",
   "metadata": {},
   "source": [
    "### Flowchart or mermaid integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73afaf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mermaid_code_agent = Agent(name=\"Mermaid Code generator\", instructions=\"You have to generate only and only mermaid code which you need to send to the tool you have to generate flowchart\", model=gemini_model)\n",
    "mermaid_tool = mermaid_code_agent.as_tool(tool_name=\"flowchart_generator\", tool_description=\"Creates a mermaid code for flowchart generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5c534b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flowchart saved to flowchart.svg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def generate_flowchart(mermaid_code: str, output_file: str = \"flowchart.svg\"):\n",
    "    \"\"\"\n",
    "    Generate a flowchart using Kroki API from Mermaid code.\n",
    "    \n",
    "    Args:\n",
    "        mermaid_code (str): Mermaid syntax describing the flowchart\n",
    "        output_file (str): Path to save the output SVG\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to saved file\n",
    "    \"\"\"\n",
    "    url = \"https://kroki.io/mermaid/svg\"\n",
    "    response = requests.post(url, data=mermaid_code.encode(\"utf-8\"))\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return output_file\n",
    "    else:\n",
    "        raise Exception(f\"Failed to generate flowchart: {response.text}\")\n",
    "\n",
    "\n",
    "# Example flowchart (Mermaid syntax)\n",
    "mermaid_code = \"\"\"\n",
    "graph TD\n",
    "    A[Sprint Planning] --> B[Sprint Backlog];\n",
    "    B --> C{Sprint};\n",
    "    \n",
    "    subgraph C [Sprint Period]\n",
    "        D[Daily Stand-ups]\n",
    "        E[Work on Backlog Items]\n",
    "    end\n",
    "    \n",
    "    C --> F[Sprint Review];\n",
    "    F --> G[Sprint Retrospective];\n",
    "    G --> A;\n",
    "\"\"\"\n",
    "\n",
    "file_path = generate_flowchart(mermaid_code)\n",
    "print(f\"Flowchart saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9303c74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.3/47.3 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "34c4f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "mermaid_agent = Agent(\n",
    "    name=\"mermaid-agent\",\n",
    "    model=gemini_model,\n",
    "    instructions=(\n",
    "        \"You are a diagram generator. Convert user requests into **valid Mermaid code** only. \"\n",
    "        \"Do not explain, only return the code block.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Wrap as tool and trace in LangSmith\n",
    "@function_tool\n",
    "@traceable(run_type=\"tool\", name=\"Mermaid Code Generator Tool\")\n",
    "def mermaid_tool(query: str):\n",
    "    \"\"\"\n",
    "    This tool uses the mermaid-agent to generate valid Mermaid code.\n",
    "    \"\"\"\n",
    "    return Runner.run_sync(mermaid_agent, query).final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "58331213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the agent with LangSmith tracing...\n",
      "\n",
      "Agent's final output:\n",
      "\n",
      "My apologies! It looks like the first flowchart had a small hiccup. Here is the corrected and clearer version for you.\n",
      "\n",
      "This diagram shows the complete loop. The arrows pointing clockwise represent the flow of **money**, and the arrows pointing counter-clockwise represent the flow of **real things** (pizzas and work).\n",
      "\n",
      "![The Circular Flow Model of Economics](circular_flow_model_v2.svg)\n",
      "\n",
      "In a nutshell, that's the circular flow model! It's a simplified but powerful way to understand the constant, circular movement of money, goods, and services throughout the economy. Your spending becomes someone else's income, and their spending can become yours.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, Runner, OpenAIChatCompletionsModel, function_tool\n",
    "from langsmith import Client, traceable\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from langchain_core.tools import tool\n",
    "from newsapi import NewsApiClient\n",
    "from agents import Agent, FileSearchTool, Runner, WebSearchTool\n",
    "import requests\n",
    "\n",
    "\n",
    "# Apply the patch for nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up LangSmith client\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "client_ls = Client()\n",
    "\n",
    "# Set up the OpenAI client for the Gemini model using the compatible endpoint\n",
    "# This is where the tool-calling issue might stem from.\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "gemini_model = OpenAIChatCompletionsModel(model=\"gemini-2.5-pro\", openai_client=gemini_client)\n",
    "\n",
    "# Initialize NewsAPI client\n",
    "newsapi = NewsApiClient(api_key=os.getenv(\"NEWSAPI_KEY\"))\n",
    "\n",
    "# Define the news fetching tool\n",
    "\n",
    "@function_tool\n",
    "@traceable(run_type=\"tool\", name=\"Fetch News Tool\")\n",
    "def fetch_news_new(query: str, language: str = \"en\", sort_by: str = \"relevancy\", max_results: int = 2):\n",
    "    \"\"\"\n",
    "    Search for articles about a given topic and return the title and description.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search keyword (e.g., 'economics', 'inflation').\n",
    "        language (str): Language of the articles (default 'en').\n",
    "        sort_by (str): The order to sort articles in ('relevancy', 'popularity', or 'publishedAt').\n",
    "        max_results (int): Number of articles to return (max 100).\n",
    "\n",
    "    Returns:\n",
    "        list of dict: A list of news articles (title and description).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use get_everything() to get both titles and descriptions\n",
    "        articles_response = newsapi.get_everything(\n",
    "            q=query,\n",
    "            language=language,\n",
    "            sort_by=sort_by,\n",
    "            page_size=max_results  # Use page_size to limit the results\n",
    "        )\n",
    "        \n",
    "        articles = articles_response.get(\"articles\", [])\n",
    "\n",
    "        # Extract only the title and description for each article\n",
    "        extracted_info = [\n",
    "            {\"title\": a.get(\"title\"), \"description\": a.get(\"description\")}\n",
    "            for a in articles\n",
    "            if a.get(\"title\") and a.get(\"description\") # Ensure both fields exist\n",
    "        ]\n",
    "        \n",
    "        return extracted_info\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "@function_tool\n",
    "@traceable(run_type=\"tool\", name=\"Fetch weather Tool\")\n",
    "def get_weather(city: str):\n",
    "    print(f\"[debug] getting weather for {city}\")\n",
    "    return f\"The weather in {city} is rainy.\"\n",
    "\n",
    "\n",
    "# Define the agent\n",
    "agent = Agent(\n",
    "    name=\"educator-agent\",\n",
    "    #model=\"litellm/gemini/gemini-1.5-flash-latest\",\n",
    "    model=gemini_model,\n",
    "    instructions=\"You are an educator. Explain concepts simply. Give real-world examples every time you explain a concept.\",\n",
    "    tools=[get_weather, fetch_news_new, mermaid_tool, generate_flowchart] # Pass the tool here\n",
    ")\n",
    "\n",
    "# Use @traceable from langsmith to trace the agent's run\n",
    "@traceable(name=\"educator-agent-run\")\n",
    "async def run_traced_agent(agent_instance, user_query):\n",
    "    \"\"\"A traced function to run the agent.\"\"\"\n",
    "    # Runner.run should handle invoking the tools if the model decides to use them\n",
    "    # and if the model/API supports it.\n",
    "    return await Runner.run(agent_instance, user_query)\n",
    "\n",
    "# Main function to run the agent\n",
    "async def main():\n",
    "    print(\"Running the agent with LangSmith tracing...\")\n",
    "    try:\n",
    "        # Example prompt that might trigger the news tool\n",
    "        result = await run_traced_agent(agent, \"Explain the circular -model of economics with a flowchart.\")\n",
    "        print(\"\\nAgent's final output:\\n\")\n",
    "        print(result.final_output)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9a92bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mermaid_agent = Agent(\n",
    "    name=\"mermaid-agent\",\n",
    "    model=gemini_model,\n",
    "    instructions=(\n",
    "        \"You are a diagram generator. Convert user requests into **valid Mermaid code** only. \"\n",
    "        \"Do not explain, only return the **valid Mermaid code**\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Wrap as tool and trace in LangSmith\n",
    "@function_tool\n",
    "@traceable(run_type=\"tool\", name=\"Mermaid Code Generator Tool\")\n",
    "def mermaid_tool(query: str):\n",
    "    \"\"\"\n",
    "    This tool uses the mermaid-agent to generate valid Mermaid code.\n",
    "    \"\"\"\n",
    "    return Runner.run_sync(mermaid_agent, query).final_output\n",
    "\n",
    "\n",
    "@function_tool\n",
    "@traceable(run_type=\"tool\", name=\"Flowchart Generator\")\n",
    "def generate_flowchart(mermaid_code: str, output_file: str = \"flowchart2.svg\"):\n",
    "    \"\"\"\n",
    "    Generate a flowchart using Kroki API from Mermaid code.\n",
    "    \n",
    "    Args:\n",
    "        mermaid_code (str): Mermaid syntax describing the flowchart\n",
    "        output_file (str): Path to save the output SVG\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to saved file\n",
    "    \"\"\"\n",
    "    url = \"https://kroki.io/mermaid/svg\"\n",
    "    response = requests.post(url, data=mermaid_code.encode(\"utf-8\"))\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return output_file\n",
    "    else:\n",
    "        raise Exception(f\"Failed to generate flowchart: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35450298",
   "metadata": {},
   "source": [
    "### Fully working Education Agent with News, Mermaid code and Flowchart generation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8fc87904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the agent with LangSmith tracing...\n",
      "\n",
      "Agent's final output:\n",
      "\n",
      "I have generated a flowchart named circular\\_flow\\_model.svg. This file should be located in the same directory where you are running this notebook.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, Runner, OpenAIChatCompletionsModel, function_tool\n",
    "from langsmith import Client, traceable\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from langchain_core.tools import tool\n",
    "from newsapi import NewsApiClient\n",
    "from agents import Agent, FileSearchTool, Runner, WebSearchTool\n",
    "import requests\n",
    "\n",
    "\n",
    "# Apply the patch for nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up LangSmith client\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "client_ls = Client()\n",
    "\n",
    "# Set up the OpenAI client for the Gemini model using the compatible endpoint\n",
    "# This is where the tool-calling issue might stem from.\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "gemini_model = OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=gemini_client)\n",
    "\n",
    "# Initialize NewsAPI client\n",
    "newsapi = NewsApiClient(api_key=os.getenv(\"NEWSAPI_KEY\"))\n",
    "\n",
    "# Define the news fetching tool\n",
    "\n",
    "@function_tool\n",
    "@traceable(run_type=\"tool\", name=\"Fetch News Tool\")\n",
    "def fetch_news_new(query: str, language: str = \"en\", sort_by: str = \"relevancy\", max_results: int = 2):\n",
    "    \"\"\"\n",
    "    Search for articles about a given topic and return the title and description.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search keyword (e.g., 'economics', 'inflation').\n",
    "        language (str): Language of the articles (default 'en').\n",
    "        sort_by (str): The order to sort articles in ('relevancy', 'popularity', or 'publishedAt').\n",
    "        max_results (int): Number of articles to return (max 100).\n",
    "\n",
    "    Returns:\n",
    "        list of dict: A list of news articles (title and description).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use get_everything() to get both titles and descriptions\n",
    "        articles_response = newsapi.get_everything(\n",
    "            q=query,\n",
    "            language=language,\n",
    "            sort_by=sort_by,\n",
    "            page_size=max_results  # Use page_size to limit the results\n",
    "        )\n",
    "        \n",
    "        articles = articles_response.get(\"articles\", [])\n",
    "\n",
    "        # Extract only the title and description for each article\n",
    "        extracted_info = [\n",
    "            {\"title\": a.get(\"title\"), \"description\": a.get(\"description\")}\n",
    "            for a in articles\n",
    "            if a.get(\"title\") and a.get(\"description\") # Ensure both fields exist\n",
    "        ]\n",
    "        \n",
    "        return extracted_info\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "@function_tool\n",
    "@traceable(run_type=\"tool\", name=\"Fetch weather Tool\")\n",
    "def get_weather(city: str):\n",
    "    print(f\"[debug] getting weather for {city}\")\n",
    "    return f\"The weather in {city} is rainy.\"\n",
    "\n",
    "\n",
    "# Define the agent\n",
    "agent = Agent(\n",
    "    name=\"educator-agent\",\n",
    "    #model=\"litellm/gemini/gemini-1.5-flash-latest\",\n",
    "    model=gemini_model,\n",
    "    instructions=\"You are an educator. Explain concepts simply. Give real-world examples every time you explain a concept.\",\n",
    "    tools=[get_weather, fetch_news_new, mermaid_tool, generate_flowchart] # Pass the tool here\n",
    ")\n",
    "\n",
    "# Use @traceable from langsmith to trace the agent's run\n",
    "@traceable(name=\"educator-agent-run\")\n",
    "async def run_traced_agent(agent_instance, user_query):\n",
    "    \"\"\"A traced function to run the agent.\"\"\"\n",
    "    # Runner.run should handle invoking the tools if the model decides to use them\n",
    "    # and if the model/API supports it.\n",
    "    return await Runner.run(agent_instance, user_query)\n",
    "\n",
    "\n",
    "mermaid_agent = Agent(\n",
    "    name=\"mermaid-agent\",\n",
    "    model=gemini_model,\n",
    "    instructions=(\n",
    "        \"You are a diagram generator. Convert user requests into **valid Mermaid code** only. \"\n",
    "        \"Do not explain, only return the **valid Mermaid code**\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Wrap as tool and trace in LangSmith\n",
    "@function_tool\n",
    "@traceable(run_type=\"tool\", name=\"Mermaid Code Generator Tool\")\n",
    "def mermaid_tool(query: str):\n",
    "    \"\"\"\n",
    "    This tool uses the mermaid-agent to generate valid Mermaid code.\n",
    "    \"\"\"\n",
    "    return Runner.run_sync(mermaid_agent, query).final_output\n",
    "\n",
    "\n",
    "@function_tool\n",
    "@traceable(run_type=\"tool\", name=\"Flowchart Generator\")\n",
    "def generate_flowchart(mermaid_code: str, output_file: str = \"flowchart2.svg\"):\n",
    "    \"\"\"\n",
    "    Generate a flowchart using Kroki API from Mermaid code.\n",
    "    \n",
    "    Args:\n",
    "        mermaid_code (str): Mermaid syntax describing the flowchart\n",
    "        output_file (str): Path to save the output SVG\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to saved file\n",
    "    \"\"\"\n",
    "    url = \"https://kroki.io/mermaid/svg\"\n",
    "    response = requests.post(url, data=mermaid_code.encode(\"utf-8\"))\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return output_file\n",
    "    else:\n",
    "        raise Exception(f\"Failed to generate flowchart: {response.text}\")\n",
    "\n",
    "# Main function to run the agent\n",
    "async def main():\n",
    "    print(\"Running the agent with LangSmith tracing...\")\n",
    "    try:\n",
    "        # Example prompt that might trigger the news tool\n",
    "        result = await run_traced_agent(agent, \"Explain the circular - model of economics with a flowchart use tools to generate mermaid code and the flowchart.\")\n",
    "        print(\"\\nAgent's final output:\\n\")\n",
    "        print(result.final_output)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a9a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
